{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b591e16e-2ab7-4eca-9c17-52a4d77daddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connexion au Data Warehouse\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "host = \"127.0.0.1\"\n",
    "port = 3307\n",
    "db = \"fashion_data_dw_project\"\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b254ca0-6555-4864-99d6-3099ea74f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  code_sale  code_customer order_code        SKU code_ship_type  \\\n",
      "0   S244495           2060  ORD405664  118458034       SHIP1209   \n",
      "1   S279244            125  ORD226537  118458034       SHIP4965   \n",
      "2   S519880           1989  ORD231649  144993001       SHIP4965   \n",
      "3   S395741            839  ORD613094  126589012       SHIP3159   \n",
      "4   S558471           1179  ORD435118  118458004       SHIP4965   \n",
      "\n",
      "  code_pricing_strategy code_payment_method  quantity               prod_name  \\\n",
      "0            TOPBAN0041             PAY1961         1    Jerry jogger bottoms   \n",
      "1            BOTH&M0012             PAY0503         3    Jerry jogger bottoms   \n",
      "2            OUTZAR0031             PAY1985         1  Mama 100 den 1p Tights   \n",
      "3            OUTMAN0029             PAY4543         1                 2p Claw   \n",
      "4            SHOANN0032             PAY5626         2    Jerry jogger bottoms   \n",
      "\n",
      "   Estimated_Unit_Price  sale_date  is_discounted  \n",
      "0                 24.99 2023-02-02              0  \n",
      "1                 24.99 2023-11-22              1  \n",
      "2                  7.99 2021-12-22              0  \n",
      "3                  4.99 2023-11-01              0  \n",
      "4                 24.99 2024-02-24              0  \n",
      "  order_code status_label         reason\n",
      "0  ORD000005    Cancelled  Payment issue\n",
      "1  ORD000006      Pending              0\n",
      "2  ORD000010      Pending              0\n",
      "3  ORD000011   Processing              0\n",
      "4  ORD000018      Pending              0\n",
      "   code_customer  Age Gender                   Zip_code Preferred_size  \\\n",
      "0              1   55   Male         Lexington_Kentucky              L   \n",
      "1              2   19   Male               Auburn_Maine              L   \n",
      "2              3   50   Male  Springfield_Massachusetts              S   \n",
      "3              4   21   Male      Cranston_Rhode Island              M   \n",
      "4              5   45   Male              Eugene_Oregon              M   \n",
      "\n",
      "   Overall_review Subscription_Status  Previous_Purchases Payment_Method  \\\n",
      "0             3.1                 Yes                  14          Venmo   \n",
      "1             3.1                 Yes                   2           Cash   \n",
      "2             3.1                 Yes                  23    Credit Card   \n",
      "3             3.5                 Yes                  49         PayPal   \n",
      "4             2.7                 Yes                  31         PayPal   \n",
      "\n",
      "  Frequency_of_Purchases  \n",
      "0            Fortnightly  \n",
      "1            Fortnightly  \n",
      "2                 Weekly  \n",
      "3                 Weekly  \n",
      "4               Annually  \n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_sql(\"SELECT * FROM fact_sales\", engine)\n",
    "dim_orders_status = pd.read_sql(\"SELECT * FROM dim_orders_status\", engine)\n",
    "customers = pd.read_sql(\"SELECT * FROM dim_customers\", engine)\n",
    "\n",
    "print(sales.head())\n",
    "print(dim_orders_status.head())\n",
    "print(customers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651dd9b9-9af2-49e0-8bd1-c11d01ea9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_status = sales.merge(\n",
    "    dim_orders_status[['order_code', 'status_label']],\n",
    "    on='order_code',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abffa371-950a-42c7-a1a4-731b956f5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_agg = sales_status.groupby('code_customer').agg(\n",
    "    total_orders=('order_code', 'count'),\n",
    "    total_cancelled=('status_label', lambda x: (x=='cancelled').sum()),\n",
    "    avg_quantity=('quantity', 'mean'),\n",
    "    avg_unit_price=('Estimated_Unit_Price', 'mean'),\n",
    "    unique_products=('SKU', pd.Series.nunique)\n",
    ").reset_index()\n",
    "\n",
    "# Calculer total_not_cancelled\n",
    "client_agg['total_not_cancelled'] = client_agg['total_orders'] - client_agg['total_cancelled']\n",
    "\n",
    "# Calculer les taux\n",
    "client_agg['cancel_rate'] = client_agg['total_cancelled'] / client_agg['total_orders']\n",
    "client_agg['not_cancelled_rate'] = client_agg['total_not_cancelled'] / client_agg['total_orders']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d518ca37-dfcb-438e-848c-4ccf0bc25f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = client_agg.merge(\n",
    "    customers[['code_customer', 'Age', 'Gender']],\n",
    "    on='code_customer',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464db0aa-eaa8-47e6-bce8-383e30530cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.rename(columns=lambda x: x.strip().lower().replace(' ', '_'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c19ee592-5c50-4e8d-9747-26587e47f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition high_risk_cancelling_customer :\n",
      "high_risk_cancelling_customer\n",
      "0    3705\n",
      "1     195\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "client_df['high_risk_cancelling_customer'] = 0\n",
    "\n",
    "num_nonzero = (client_df['cancel_rate'] > 0).sum()\n",
    "\n",
    "if num_nonzero > 0:\n",
    "    nonzero_cancel = client_df[client_df['cancel_rate'] > 0]\n",
    "    percentile_threshold = nonzero_cancel['cancel_rate'].quantile(0.80)\n",
    "    client_df.loc[nonzero_cancel.index, 'high_risk_cancelling_customer'] = \\\n",
    "        nonzero_cancel['cancel_rate'].apply(lambda x: 1 if x >= percentile_threshold else 0)\n",
    "\n",
    "num_high_risk_forced = max(1, int(0.05 * len(client_df)))  # 5% des clients\n",
    "high_risk_indices = client_df.sample(num_high_risk_forced, random_state=42).index\n",
    "client_df.loc[high_risk_indices, 'high_risk_cancelling_customer'] = 1\n",
    "\n",
    "# Vérifier la répartition\n",
    "print(\"Répartition high_risk_cancelling_customer :\")\n",
    "print(client_df['high_risk_cancelling_customer'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be2f6b9-1a64-4cb1-948e-c41335d8bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = client_df.drop(['code_customer', 'cancel_rate', 'not_cancelled_rate', 'high_risk_cancelling_customer', 'gender'], axis=1)\n",
    "X['gender_male'] = (client_df['gender'] == 'Male').astype(int)\n",
    "y = client_df['high_risk_cancelling_customer']\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7041386b-e598-4491-8df1-14cd337bd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177ff39a-f7d5-4bbd-8ffb-97b819a3387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes après SMOTE : high_risk_cancelling_customer\n",
      "0    2964\n",
      "1    2964\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Classes après SMOTE :\", pd.Series(y_train_res).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d92cf1c9-c55c-49b0-95be-2f21e36f74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGBoost =====\n",
      "Accuracy: 0.9256\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       741\n",
      "           1       0.09      0.05      0.06        39\n",
      "\n",
      "    accuracy                           0.93       780\n",
      "   macro avg       0.52      0.51      0.51       780\n",
      "weighted avg       0.91      0.93      0.92       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[720  21]\n",
      " [ 37   2]]\n",
      "\n",
      "===== LogisticRegression =====\n",
      "Accuracy: 0.5551\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71       741\n",
      "           1       0.04      0.33      0.07        39\n",
      "\n",
      "    accuracy                           0.56       780\n",
      "   macro avg       0.49      0.45      0.39       780\n",
      "weighted avg       0.90      0.56      0.68       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[420 321]\n",
      " [ 26  13]]\n",
      "\n",
      "===== SVM =====\n",
      "Accuracy: 0.6308\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.65      0.77       741\n",
      "           1       0.05      0.36      0.09        39\n",
      "\n",
      "    accuracy                           0.63       780\n",
      "   macro avg       0.50      0.50      0.43       780\n",
      "weighted avg       0.91      0.63      0.73       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[478 263]\n",
      " [ 25  14]]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9c8aca-5631-4090-b709-8ba9b39d3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3385edf7-700d-4232-982e-5f91c64654b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21629\\Documents\\3eme LIG\\MMe.hochlef\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:03:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.9153846153846154\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       741\n",
      "           1       0.03      0.03      0.03        39\n",
      "\n",
      "    accuracy                           0.92       780\n",
      "   macro avg       0.49      0.49      0.49       780\n",
      "weighted avg       0.90      0.92      0.91       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[713  28]\n",
      " [ 38   1]]\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# scale_pos_weight\n",
    "scale = len(y_train_res[y_train_res==0]) / len(y_train_res[y_train_res==1])\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42, use_label_encoder=False, scale_pos_weight=scale)\n",
    "\n",
    "# pour hyperparamètres\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3,5],\n",
    "    'learning_rate': [0.01,0.1]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_xgb = GridSearchCV(xgb, param_grid_xgb, scoring='f1', cv=cv, n_jobs=-1)\n",
    "grid_xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 4️ Évaluation\n",
    "y_pred_xgb = grid_xgb.predict(X_test)\n",
    "print(\"Best params:\", grid_xgb.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c5e47e-5387-40db-ad77-e6a7eda6fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 0.5551282051282052\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71       741\n",
      "           1       0.04      0.33      0.07        39\n",
      "\n",
      "    accuracy                           0.56       780\n",
      "   macro avg       0.49      0.45      0.39       780\n",
      "weighted avg       0.90      0.56      0.68       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[420 321]\n",
      " [ 26  13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Oversampling avec SMOTE\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# class_weight='balanced'\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "\n",
    "# 3️ GridSearchCV\n",
    "param_grid_lr = {'C':[0.1,1,10], 'penalty':['l2'], 'solver':['lbfgs']}\n",
    "grid_lr = GridSearchCV(lr, param_grid_lr, scoring='f1', cv=cv, n_jobs=-1)\n",
    "grid_lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 4️ Évaluation\n",
    "y_pred_lr = grid_lr.predict(X_test)\n",
    "print(\"Best params:\", grid_lr.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b458e7e5-1a99-4c3d-bdf9-89d0ea86d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Accuracy: 0.8474358974358974\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       741\n",
      "           1       0.05      0.10      0.06        39\n",
      "\n",
      "    accuracy                           0.85       780\n",
      "   macro avg       0.50      0.49      0.49       780\n",
      "weighted avg       0.90      0.85      0.87       780\n",
      "\n",
      "Confusion Matrix:\n",
      " [[657  84]\n",
      " [ 35   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Oversampling avec SMOTE\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# class_weight='balanced'\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced')\n",
    "\n",
    "# GridSearchCV\n",
    "param_grid_svm = {'C':[0.1,1,10], 'gamma':[0.01,0.1,1], 'kernel':['rbf']}\n",
    "grid_svm = GridSearchCV(svm, param_grid_svm, scoring='f1', cv=cv, n_jobs=-1)\n",
    "grid_svm.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 4️ Évaluation\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print(\"Best params:\", grid_svm.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90405d-9652-4579-a056-7fc1922a2d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
